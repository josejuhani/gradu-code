{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline \n",
    "import os\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradutil as gu\n",
    "import simplejson as json\n",
    "import interactiveBoreal as ib\n",
    "import matplotlib.pyplot as plt\n",
    "from ASF import ASF, NIMBUS\n",
    "from time import time\n",
    "from pyomo.opt import SolverFactory\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kehys = ib.ReferenceFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_dict.json', 'r') as f:\n",
    "    new_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = new_dict['centers']\n",
    "wn = new_dict['weights']\n",
    "xt = new_dict['xtoc']\n",
    "on = new_dict['out_centers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kehys.centers = np.array(cn)\n",
    "kehys.weights = np.array(wn)\n",
    "kehys.xtoc = np.array(xt)\n",
    "kehys.out_centers = np.array(on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%time\n",
    "nclust = 600\n",
    "seedn = 6\n",
    "kehys.cluster(nclust=nclust, seedn=seedn)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "with open('best_dict.json', 'w') as fi:\n",
    "    json.dump(new_dict, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kehys.centers\n",
    "nvar = len(kehys.x_norm)\n",
    "weights = kehys.weights/nvar\n",
    "solver_name = 'cplex'\n",
    "hectars = 68700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ide = kehys.normalize_ref(kehys.ideal)\n",
    "nad = kehys.normalize_ref(kehys.nadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalarize(init_ref, frees=[]):\n",
    "    ref = kehys.normalize_ref(init_ref)\n",
    "    asf1   = ASF(ide, nad, ref, data, weights=weights, nvar=nvar, scalarization='asf', sense='maximize')\n",
    "    stom1  = ASF(ide, nad, ref, data, weights=weights, nvar=nvar, scalarization='stom', sense='maximize')\n",
    "    guess1 = ASF(ide, nad, ref, data, weights=weights, nvar=nvar, scalarization='guess',sense='maximize', frees=frees)\n",
    "\n",
    "    asf_solver1 = ib.Solver(asf1.model, solver=solver_name)\n",
    "    asf_res1 = asf_solver1.solve()\n",
    "    print(asf_res1['Solver'][0]['Termination condition'])\n",
    "\n",
    "    stom_solver1 = ib.Solver(stom1.model, solver=solver_name)\n",
    "    stom_res1 = stom_solver1.solve()\n",
    "    print(stom_res1['Solver'][0]['Termination condition'])\n",
    "\n",
    "    guess_solver1 = ib.Solver(guess1.model, solver=solver_name)\n",
    "    guess_res1 = guess_solver1.solve()\n",
    "    print(guess_res1['Solver'][0]['Termination condition'])\n",
    "\n",
    "    asf_values1   = kehys.values(model=asf1.model)\n",
    "    stom_values1  = kehys.values(model=stom1.model)\n",
    "    guess_values1 = kehys.values(model=guess1.model)\n",
    "    \n",
    "    return asf_values1, stom_values1, guess_values1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try some reference points that were actually used in the interactive solving earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyle1 = np.array((3266, 51.85, 2.103, 0.229))\n",
    "ref1 = kyle1*hectars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyle2 = np.array((3500, 50., 2., 0.22))\n",
    "ref2 = kyle2*hectars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res1 = np.array(scalarize(ref1))/hectars\n",
    "for r in res1:\n",
    "    print(['{:7.2f}'.format(value) for value in r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in kyle1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the results look good, even though the first objective was way too optimistic back then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res2 = np.array((scalarize(ref2)))/hectars\n",
    "for r in res2:\n",
    "     print(['{:7.2f}'.format(value) for value in r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in kyle2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here it looks pretty much the same than with the previous one. Great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIMBUS testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we try the NIMBUS scalarization, using the results of the first ACH scalarization as a starting point.\n",
    "The results were displayd per hectar, so we need to remember scale them to the full scale and then normalize for the NIMBUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set classification so that starting from the asf-result\n",
    "of the previous problem:\n",
    "1) the first objective should improve as much as possible,\n",
    "2) the second detoriate to a 4.5+01, \n",
    "3) the third stay the same and \n",
    "4) the fourth change freely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1 = res1[0]*hectars\n",
    "kyle1_ref = np.array((kehys.ideal[0], 4.5e+01*hectars, start1[2], kehys.nadir[3]))\n",
    "nimbus1_ref = kehys.normalize_ref(kyle1_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The classes whose 'distance' to the Pareto front are to be\n",
    "minized, i.e. the objectives to improve as much as possible and\n",
    "the ones to improve to a limit'''\n",
    "minmax1 = np.array([0], dtype=int)\n",
    "''' The classes whose values are to be kept the same.'''\n",
    "stay1 = np.array([2], dtype=int)\n",
    "''' The classes whose values are to be deteriorated to a limit'''\n",
    "detoriate1 = np.array([1], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimbus1 = NIMBUS(ide, nad, nimbus1_ref, data, \n",
    "                 minmax1, stay1, detoriate1, kehys.normalize_ref(start1), \n",
    "                 weights=weights, nvar=nvar)\n",
    "nimbus1_solver = ib.Solver(nimbus1.model, solver=solver_name)\n",
    "nimbus1_res = nimbus1_solver.solve()  #output=True)  #, keepfiles=True)\n",
    "nimbus1_values = kehys.values(model=nimbus1.model)\n",
    "str(nimbus1_res['Solver'][0]['Termination condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in nimbus1_values/hectars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nimbus was supposed to improve the first objective as much as possible, detoriate the\n",
    "second to a 4.5e+01, the third stay the same and the fourth change freely. The starting point is presented in the below, so everything looks pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in start1/hectars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set classification so that starting from the same asf-result than before:\n",
    "1) the first objective should change freely, \n",
    "2) the second improve to 5.5e+01, \n",
    "3) the third improve as much as possible and \n",
    "4) the fourth stay the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyle2_ref = np.array((kehys.nadir[0], 5.5e+01*hectars, kehys.ideal[2], start1[3]))\n",
    "nimbus2_ref = kehys.normalize_ref(kyle2_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The classes whose 'distance' to the Pareto front are to be\n",
    "minized, i.e. the objectives to improve as much as possible and\n",
    "the ones to improve to a limit'''\n",
    "minmax2 = np.array([1,2], dtype=int)\n",
    "''' The classes whose values are to be kept the same.'''\n",
    "stay2 = np.array([3], dtype=int)\n",
    "''' The classes whose values are to be deteriorated to a limit'''\n",
    "detoriate2 = np.array([], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimbus2 = NIMBUS(ide, nad, nimbus2_ref, data, minmax2, \n",
    "                 stay2, detoriate2, kehys.normalize_ref(start1), weights=weights, nvar=nvar)\n",
    "nimbus2_solver = ib.Solver(nimbus2.model, solver=solver_name)\n",
    "nimbus2_res = nimbus2_solver.solve()  # output=True, keepfiles=True)\n",
    "nimbus2_values = kehys.values(model=nimbus2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in nimbus2_values/hectars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there seems to be something wrong with the second objective getting too good and the fourth not staying the same, we try using the other scalarizing for the same preferences and see if we get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(['{:7.2f}'.format(value) for value in start1/hectars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying by using scalarizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets try what we get if using the classification information of the NIMBUS as a reference point for the other scalarizings. Notice how (guess) scalarization has to be told what objective is free to change as it wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res3 = np.array((scalarize(kyle2_ref, frees=[0])))/hectars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in res3:\n",
    "    print(['{:7.2f}'.format(value) for value in r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks like that all the scalarizings agree about the results so probably this is so then. So be it."
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}